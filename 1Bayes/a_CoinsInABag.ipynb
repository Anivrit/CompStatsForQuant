{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Coins in a bag: Bayesian updating/inference\n",
    "\n",
    "### Aims of this notebook:\n",
    "1. Write out the mathematics for conditional probability and then elevating this to a Bayesian view of things\n",
    "2. Add in the likelihood to the `CoinFlip` class (is there a better way to define `nCr` (i.e. use an existing `scipy` function)\n",
    "3. Add in fucntionality to update multiple times and show that this gives the same results as before\n",
    "4. Show that we can use a non-uniform prior to show a belief and show how convergence time changes when we are sure and when we are unsure\n",
    "5. look at a cosomological model (or any other two parameter system)\n",
    "\n",
    "### Notebook structure:\n",
    "1. Conditional probabilities and Bayes' rule\n",
    "2. Elevating to probability distributions\n",
    "3. Generalising to a 100-coin bag\n",
    "4. Bayesian updating\n",
    "5. Non-uniform priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. Conditional proabilities and Bayes' rule\n",
    "\n",
    "For this notebook, we assume that you are familiar with Bayes' rule for [conditional probabilities](https://en.wikipedia.org/wiki/Conditional_probability):\n",
    "\n",
    "$$P(A|B) =  \\frac{P(B|A) P(A)}{P(B)} $$\n",
    "\n",
    "Lets apply this equation to an example where we have a bag with two coins, one is a fair coin and the other has a heads on both sides. We pick one coin out of the bag at random and flip it twice and get HH. Using conditional probabilities and Bayes' rule we can update our probabilities of which coin we might have (which before the flips is 50/50). Therefore Bayes' rule becomes:\n",
    "\n",
    "$$P(B|HH) =  \\frac{P(HH|B) P(B)}{P(HH)} $$\n",
    "\n",
    "$P(HH|B) = 1$ as the doubled-headed coin can only flips heads\n",
    "\n",
    "$P(B) = 0.5$ before flipping we pick one of two coins with equal probability\n",
    "\n",
    "$P(HH) = 0.5 \\cdot 1^2 + 0.5 \\cdot 0.5^2 = 0.375$\n",
    "\n",
    "$$P(B|HH) =  \\frac{P(HH|B) P(B)}{P(HH)} = \\frac{1 \\cdot 0.5}{0.625} = 0.8$$\n",
    "\n",
    "![PMF_Two_Coins](figs/pmf_twocoins.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2. Elevating to probability distributions\n",
    "\n",
    "We can now try and look at the same problem through the lens of probability distributions, to do this we need to define the prior, likelihood and posterior. \n",
    "\n",
    "### Prior, $\\pi (\\theta)$\n",
    "The prior distribution is a probability distribution of our prior beliefs of the parameters of the system before we've seen any data. \n",
    "\n",
    "In the case of our two coins in a bag, the parameter of the model $\\theta$ is the *bias* of the coin we picked, $p$. Before actually flipping the coin, we believe there is an equal chance that we picked a coin with $p=0.5$ or $p=1$. This is known as a *uniform prior* as the probability distribution over the values of parameters in the model is uniform. We will look later at non-uniform priors and when to use them.\n",
    "\n",
    "### Likelihood, $\\mathcal L(D | \\theta)$\n",
    "The likelihood describes how likely we are to observe some data, given the parameters of the model.\n",
    "\n",
    "In our case where we are flipping coins we notice that each flip has just two outcomes and therefore many flips will follow a [binomial distribution](#), having the formula for this binomial distribution becomes necessary for more non-trivial cases (i.e. $>2$ flips).\n",
    "\n",
    "### Posterior, $P(\\theta | D)$\n",
    "The posterior is the probability distribution over the model paramters which we get after updating the prior using our data\n",
    "\n",
    "\n",
    "This gives us an analogous expression for Bayes' rule for distributions:\n",
    "\n",
    "$$P(\\theta | D) = \\frac{\\mathcal L(D | \\theta) \\cdot \\pi(\\theta) }{ P(D)}$$\n",
    "\n",
    "N.B all distributions in our case theta domain $[0,1]$ and therefore we can multiply two distributions together by multiplying elementwise (this how `numpy` works out of the box). Distributions are vectors and not continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercise: Constructing the Likelihood, $\\mathcal L(D | \\theta)$\n",
    "\n",
    "The likelihood, $\\mathcal L (D_N | p)$ for a coin with bias $p$ is the probability of seeing a given outcome of $N$ coin flips, this follows a binomial distribution. \n",
    "\n",
    "Fill in your code for the function definition below using the type hints of the inputs and outputs along with the form of `data` as given in the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def likelihood(data: np.array(bool), p: np.array(float)) -> np.array(float):\n",
    "    '''\n",
    "    YOUR CODE HERE!\n",
    "\n",
    "    Hint: use `math.comb()`\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert likelihood(data=[True, True], p=0.5) == 0.25\n",
    "assert likelihood(data=[True, True, False], p=0.5) == 3/8\n",
    "assert likelihood(data=[True], p=0) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercise: Constructing the Posterior, $P( \\theta | D)$\n",
    "\n",
    "Now use the your likelihood function in Bayes' rule to calculate the posterior. Note how we didn't define $P(D)$ earlier, this is becuase we use it as a normalising factor, though this term is known as the *model evidence* which has many subtleties that go beyond the scope of this tutorial. Therefore, for now, we always want our posteriors (and priors) to be normalised ($\\sum_i P(p_i | D) = 1$).\n",
    "\n",
    "When generating a posterior for a given coin flip data, we can run a couple of sense checks on the results. If we see a single TAILS in the data, then our probability of having the $p=1$ coin is 0. We should also check that the probabilities calculated by hand in (Ex.A) agree with the program.\n",
    "\n",
    "Fill out the function definitions below using the again using type hints\n",
    "\n",
    "if you construct a function using existing vectorised `numpy` functions, and the operations within that function are element-wise, your new function will also be vectorised (this is the likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def posterior(data: np.array(bool), theta: float, prior: np.array(float)) -> np.array(float):\n",
    "    '''\n",
    "    YOUR CODE HERE!\n",
    "\n",
    "    Hint: \n",
    "    this is possible with `numpy` vectorisation (i.e. no loops) \n",
    "\n",
    "    as `likelihood()` acts on single elements it is also vectorised\n",
    "\n",
    "    if vectorisation is unfamiliar try with loops first\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    posterior(data=np.array([True, True]), theta=np.array([0.5,1]), prior=np.array([0.5,0.5])),\n",
    "    np.array([0.2,0.8])\n",
    ")\n",
    "\n",
    "assert np.allclose(\n",
    "    posterior(data=np.array([True, False]), theta=np.array([0,0.5, 1]), prior=np.array([1/3,1/3,1/3])), \n",
    "    np.array([0,1,0])\n",
    ")\n",
    "\n",
    "assert np.allclose(\n",
    "    posterior(data=np.array([True, True]), theta=np.array([0,0.25,0.5,0.75,1]), prior=np.array([0.2,0.2,0.2,0.2,0.2])), \n",
    "    np.array([0.        , 0.03333333, 0.13333333, 0.3       , 0.53333333])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Intuition building w/ self generated data \n",
    "\n",
    "data = np.array([\n",
    "    # YOUR SEQUENCE\n",
    "])\n",
    "\n",
    "# unit tests here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3. Generalising for an 100-coin bag\n",
    "\n",
    "Using probability distributions quickly becomes a far better framework than the conditional probability case when we consider using many coins in a bag. For example, consider $100$ coins with biases, $ p = [0.00,0.01,0.02,\\cdots,0.99]$. Our functions above work with no modifications whereas the conditional case would require a lot of fiddly algebra. \n",
    "\n",
    "Now lets pick one coin from the bag at random and flip it 10 times. As we've picked the coin randomly our prior, $\\pi(p)$ is uniform over $p \\in [0,1]$. Now we flip the coin $N=10$ times and realise an outcome of H and T. For examples, we may get 7H 3T which in the order given by: \n",
    "\n",
    "```\n",
    "data = [True, False, True, True, True, False, True, False, True, True]\n",
    "```\n",
    "\n",
    "We use this data to calculate a posterior distribution. Intuitively, we expect the likelihood to be peaked at $p=0.7$, this peak will propagate into the posterior as we have a uniform prior. \n",
    "\n",
    "Intuitively, we expect the posterior to be peaked at $p=0.7$ and be zero for $p=0$ and $p=1$. We have used this sequence of 10 flips to inform us that the coin we picked from the bag likely has some bias towards heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDefine your coin bias parameters and prior vectors\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Define your coin bias parameters and prior vectors\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercise: Creating data and flipping coins\n",
    "\n",
    "First, we need a way to create random data systematically to test our functions. This should produce a `numpy` array of boolean values, again, with `True` for H and `False` for T. \n",
    "\n",
    "Then you should plot the posterior assuming we picked a coin with, say `true_p = 0.2`, and see that the posterior will form a peak around this value which gets sharper as we increase this number of flips.\n",
    "\n",
    "The sharpness of the peak reflects our confidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data(true_p: float, N_flips: int) -> np.array(bool):\n",
    "    '''\n",
    "    YOUR CODE HERE!\n",
    "\n",
    "    Hint: \n",
    "    `np.random.random()`\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mean and variance assertions? \n",
    "\n",
    "true_p = 0.2\n",
    "N_flips = 100000\n",
    "\n",
    "assert np.isclose(\n",
    "    create_data(true_p=true_p, N_flips=N_flips).mean(), \n",
    "    true_p,\n",
    "    rtol=1e-2\n",
    ")\n",
    "\n",
    "# 3 std devs\n",
    "assert create_data(true_p=true_p, N_flips=N_flips).var() <  3 * true_p * (1 - true_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bayesian updating\n",
    "\n",
    "In this section we explore Bayesian updating. The idea is to use the calculated posterior for some inital observed data, and then set this as our new prior when awaiting for further data. In this way, we use our initial observations to update our expecations for future data, assuming we are still sampling from the same distribution (i.e. flipping same coin with `true_p`).\n",
    "\n",
    "Assuming we start with a uniform initial prior, the updating process for updating data in batches $(D_1, D_2, \\cdots)$ looks schematically as\n",
    "$$ \\pi_0(\\theta) = \\text{Uniform}(0,1) $$\n",
    "$$\\pi_1(\\theta) \\leftarrow P (\\theta | D_1)$$\n",
    "$$\\pi_2(\\theta) \\leftarrow P (\\theta | D_2)$$\n",
    "\n",
    "We can explore this updating process by writing a function using `create_data()` and then splitting this in multiple sets of data i.e. a dataset. \n",
    "\n",
    "e.g. `data = [True, False, False, True] -> dataset = [[True, False], [False, True]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(true_p: float, N_flips: int, M_sets: int) -> list[np.array(bool)]:\n",
    "    '''\n",
    "    YOUR CODE HERE!\n",
    "\n",
    "    maybe we call create_data in here? \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to see what the posterior looks like after every batch of new data, using our new prior (the calculated posterior after the old set of data). \n",
    "\n",
    "To neatly package this into one function, we pass the dataset as a list of $M$ sets of data, and return out $M$ posteriors: $P_1(p | D_1), P_2(p | D_1 \\cup D_2), \\cdots, P_M(p | D) $, where we are continuously updating the prior each time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_update(dataset: list[np.array(bool)], theta: np.array(float), prior: np.array(float)) -> list[np.array(float)]:\n",
    "    '''\n",
    "    YOUR CODE HERE!\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot a graph of all the posteriors as the data streams in. Your graph should look something like this\n",
    "\n",
    "![Bayes_Updating](figs/bayesian_updating.png)\n",
    "\n",
    "We also expect that repeatedly updating the posterior as new data comes in should still give the same final posterior as if we were to just perform a single inference on the whole dataset from the beginning.\n",
    "$$P_M(p | D_1 \\cup D_2 \\cdots \\cup D_M) = P(p | D)$$\n",
    "And we should verify this is the case for our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(true_p=0.2, N_flips=100, M_sets=5)\n",
    "data = np.hstack(dataset)\n",
    "\n",
    "assert np.allclose(\n",
    "    posterior(data, p, prior).astype('float'),\n",
    "    bayes_update(dataset, p, prior)[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Piecewise uniform priors\n",
    "\n",
    "Having developed a full workflow for tackling problems with bayesian inference let's explore non-uniform priors i.e. before any data is seen we have an opinion on what the bias may be. \n",
    "\n",
    "Consider the case where Bob, hands you a coin and says *'this coin is biased towards tails, but remember I lie x% of the time'* (i.e. $0 < p < 0.5$ x% of the time and $0.5<p<1$ (100-x)% of the time).\n",
    "\n",
    "We can encode this by using a piecewise-uniform prior\n",
    "\n",
    "$$\\pi =  \n",
    "\\begin{cases} \n",
    "x/0.5, \\qquad 0 < p < 0.5 \\\\\n",
    "(1-x)/0.5, \\quad 0.5 < p < 1\n",
    "\\end{cases}$$\n",
    "\n",
    "Now lets repeat the above analysis using bayesian updating for a dataset consisting of 5 sets of 10 flips. In the first case, Bob wasn't lying and $p_\\text{true} = 0.25$. In the second case, Bob was lying and $p_\\text{true} = 0.75$. \n",
    "\n",
    "As expected when Bob isn't lying our graph converges towards $p_\\text{true}$ normally. Interestingly, when Bob is lying, although after all 5 sets of flips the posterior looks closely matches that to when Bob is telling the truth. For the first and second posterior we get a bimodal distribution meaning we are not sure about whether to trust our data or our prior. \n",
    "\n",
    "This shows that for sparse data regimes, the choice of prior is important but for regimes where there is lots of data it is much less important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "The two interesting cases to look at are when our prior guess is right, such that $p_{\\mu} \\approx p_{\\text{true}}$ and when our prior is very wrong, so we have been tricked and were given a coin with bias very different to what we thought. \n",
    "\n",
    "![Non_Uniform_Bayes](figs/non_uniform.png)\n",
    "\n",
    "In the bottom graph we see when our prior is right, each of the updated posteriors rapidly converges to the true value, with a more spiked (confident) distribution. However, when we have been tricked and our prior is very wrong, the posteriors are 'dragged' away from our prior as more and more data flows in. This reflects the balance between our initial opinion that a coin with $p_{\\text{true}}=0.1$ is very unlikely, combined with the fact that we keep flipping tails over and over. It is interesting to see that even for only $N=100$ flips total, the posterior has moved significantly away from the initial prior.\n",
    "\n",
    "Choosing a good prior can become very important when working with more complicated models. For example, in a 100-dimensional bayesian inference, the volume of posterior space to explore becomes huge and the process of converging our prior onto the true posterior becomes exponentially slower. Therefore choosing a prior which is accurate can drastically reduce the amount of data and computational resources required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
